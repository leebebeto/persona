{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../logs/rho100/DASTC__2020-07-01-01-18.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../logs/imdb_lyrics_10.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path , 'rb') as f:\n",
    "    pk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'iteration': 100,\n",
       " 'domain_acc': 0.7770061728395061,\n",
       " 'transfer_acc': 0.48148148148148145,\n",
       " 'blue': 0.04684147540877836}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic \n",
    "* Epoch line 찾기\n",
    "* Evaluate target domain 찾기\n",
    "* domain acc: [0-9].*[0-9]\n",
    "* transfer_acc: [0-9].*[0-9]\n",
    "* Blue score:\n",
    "* iteration 100 씩 더하다가 epoch 찾으면 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = re.compile('epoch [0-9]*[0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = p.search('epoch 3 dfdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7)\n"
     ]
    }
   ],
   "source": [
    "print(m.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2pickle(fpath, rho):\n",
    "    \n",
    "    with open(fpath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    pre_list = []\n",
    "    p_epoch = re.compile('epoch [0-9]*[0-9]')\n",
    "    p_do = re.compile('domain acc: [0-9].*[0-9]')\n",
    "    p_tr = re.compile('transfer acc: [0-9].*[0-9]')\n",
    "    p_bl = re.compile('Bleu score: [0-9].*[0-9]')\n",
    "    p_save =re.compile('Saving style transfer model')\n",
    "    temp_dict = {}\n",
    "    epoch=0\n",
    "    iteration = 100\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "\n",
    "        m = p_epoch.search(line)\n",
    "        if m :\n",
    "            epoch = int(m.group().split()[-1])\n",
    "            iteration = 100\n",
    "\n",
    "        m_do = p_do.search(line)\n",
    "\n",
    "        if m_do :\n",
    "            domain_acc = float(m_do.group().split()[-1])\n",
    "\n",
    "        m_tr = p_tr.search(line)\n",
    "\n",
    "        if m_tr:\n",
    "            transfer_acc = float(m_tr.group().split()[-1])\n",
    "\n",
    "\n",
    "        m_bl = p_bl.search(line)\n",
    "\n",
    "        if m_bl:\n",
    "            blue = float(m_bl.group().split()[-1])\n",
    "\n",
    "        m_save = p_save.search(line)\n",
    "\n",
    "        if m_save:\n",
    "            # Append!\n",
    "            pre_list.append({'epoch':epoch,'domain_acc':domain_acc,'transfer_acc':transfer_acc,'blue':blue, 'iteration':iteration})\n",
    "            iteration += 100\n",
    "            \n",
    "    pickle_file_name = '../logs/' + 'rho_' + str(rho) + '.pickle'\n",
    "    \n",
    "    with open(pickle_file_name,'wb') as f:\n",
    "        pickle.dump(pre_list, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_list = []\n",
    "p_epoch = re.compile('epoch [0-9]*[0-9]')\n",
    "p_do = re.compile('domain acc: [0-9].*[0-9]')\n",
    "p_tr = re.compile('transfer acc: [0-9].*[0-9]')\n",
    "p_bl = re.compile('Bleu score: [0-9].*[0-9]')\n",
    "p_save =re.compile('Saving style transfer model')\n",
    "temp_dict = {}\n",
    "epoch=0\n",
    "iteration = 100\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    \n",
    "    m = p_epoch.search(line)\n",
    "    if m :\n",
    "        epoch = int(m.group().split()[-1])\n",
    "        iteration = 100\n",
    "    \n",
    "    m_do = p_do.search(line)\n",
    "    \n",
    "    if m_do :\n",
    "        domain_acc = float(m_do.group().split()[-1])\n",
    "        \n",
    "    m_tr = p_tr.search(line)\n",
    "\n",
    "    if m_tr:\n",
    "        transfer_acc = float(m_tr.group().split()[-1])\n",
    "        \n",
    "    \n",
    "    m_bl = p_bl.search(line)\n",
    "\n",
    "    if m_bl:\n",
    "        blue = float(m_bl.group().split()[-1])\n",
    "    \n",
    "    m_save = p_save.search(line)\n",
    "    \n",
    "    if m_save:\n",
    "        # Append!\n",
    "        pre_list.append({'epoch':epoch,'domain_acc':domain_acc,'transfer_acc':transfer_acc,'blue':blue, 'iteration':iteration})\n",
    "        iteration += 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change log 2 pickle\n",
    "for rho in [1,5,10,25,100]:\n",
    "    log2pickle(log_file_path,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.makedirs('vis', exist_ok = True)\n",
    "os.makedirs('transfer_list', exist_ok = True)\n",
    "\n",
    "rho = 1\n",
    "\n",
    "\n",
    "# load losses\n",
    "#with open('logs/' + 'rho' + str(rho) + '.pickle', 'rb') as f:\n",
    "#\tdata = pickle.load(f)\n",
    "data=pre_list\n",
    "\n",
    "iter_list = [float(item['iteration']) for item in data][:-1]\n",
    "domain_list = [float(item['domain_acc']) for item in data][:-1]\n",
    "transfer_list = [float(item['transfer_acc']) for item in data][:-1]\n",
    "bleu_list = [float(item['blue']) for item in data][:-1]\n",
    "\n",
    "plt.plot(iter_list, domain_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Domain Accuracy')\n",
    "plt.savefig('vis/pretrain_epoch_'+str(rho)+'_domain_acc' +'.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(iter_list, transfer_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Transfer Accuracy')\n",
    "plt.savefig('vis/pretrain_epoch_'+str(rho)+'_transfer_acc' +'.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(iter_list, bleu_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Bleu Score')\n",
    "plt.savefig('vis/pretrain_epoch_'+str(rho)+'_bleu_score' +'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'iteration': 100,\n",
       " 'domain_acc': 0.7770061728395061,\n",
       " 'transfer_acc': 0.48148148148148145,\n",
       " 'blue': 0.04684147540877836}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_dict = {}\n",
    "transfer_dict = {}\n",
    "\n",
    "sample_sentences=[\n",
    "\t'but i can not help it that i can not take my eyes off of you',\n",
    "\t'and I am a man of expanding so why should i stand in her way',\n",
    "\t'and i swear by the moon and the stars in the sky ill be there',\n",
    "\t'baby I am baby I am hurt and i do not want to play anymore',\n",
    "\t'then I am willing to wait for it wait for it wait for it',\n",
    "\t'every inch of your skin is a holy gray I have got to find',\n",
    "\t'i never thought that you would be the one to hold my heart',\n",
    "\t'if she changes her mind this is the first place she will go',\n",
    "\t'oh her eyes her eyes make the stars look like they are not shinin']\n",
    "\n",
    "total_dict = {}\n",
    "for i in range(1,21):\n",
    "\toriginal_result, reconstruction_result, transfer_result =[], [], []  \n",
    "\tselect_epoch = i\n",
    "\t# load sample sentences\n",
    "\twith open('logs/'+ str(pretrain_epoch) + '/' + 'domain_adapt/target/epoch'+ str(select_epoch) + '_reconstruction.txt', 'r') as f1:\n",
    "\t\treconstruction = f1.readlines()\n",
    "\twith open('logs/'+ str(pretrain_epoch) + '/' + 'domain_adapt/target/epoch'+ str(select_epoch) + '_transfer.txt', 'r') as f2:\n",
    "\t\ttransfer = f2.readlines()\n",
    "\tfor recon in reconstruction:\n",
    "\t\tif recon.split('\\t')[0] in sample_sentences:\n",
    "\t\t\toriginal_result.append(recon.split('\\t')[0]) \n",
    "\t\t\treconstruction_result.append(recon.split('\\t')[1]) \n",
    "\n",
    "\tfor trans in transfer:\n",
    "\t\tif trans.split('\\t')[0] in sample_sentences:\n",
    "\t\t\ttransfer_result.append(trans.split('\\t')[1]) \n",
    "\n",
    "\ttotal_dict[i] = {'original': original_result, 'recon': reconstruction_result, 'transfer': transfer_result}\n",
    "\t\n",
    "\n",
    "with open('transfer_list/sample_result_' + str(pretrain_epoch) + '.pickle', 'wb') as result:\n",
    "\tpickle.dump(total_dict, result)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_term",
   "language": "python",
   "name": "nlp_term"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
